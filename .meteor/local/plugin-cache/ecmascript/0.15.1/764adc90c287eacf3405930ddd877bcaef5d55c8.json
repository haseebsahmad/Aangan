{"metadata":{},"options":{"assumptions":{},"compact":false,"sourceMaps":true,"ast":true,"babelrc":false,"configFile":false,"parserOpts":{"sourceType":"module","sourceFileName":"C:\\Users\\Haseeb\\Desktop\\Aangan-main\\Aangan-main\\packages\\cfs:tempstore\\tempStore.js","plugins":["*","flow","jsx","asyncGenerators","bigInt","classPrivateMethods","classPrivateProperties","classProperties","doExpressions","dynamicImport","exportDefaultFrom","exportExtensions","exportNamespaceFrom","functionBind","functionSent","importMeta","nullishCoalescingOperator","numericSeparator","objectRestSpread","optionalCatchBinding","optionalChaining",["pipelineOperator",{"proposal":"minimal"}],"throwExpressions","objectRestSpread","objectRestSpread","asyncGenerators","classProperties","classPrivateProperties","jsx","nullishCoalescingOperator","nullishCoalescingOperator","optionalChaining","optionalChaining","optionalCatchBinding","optionalCatchBinding","classProperties","classPrivateProperties","classPrivateMethods","classProperties","classPrivateProperties","asyncGenerators","asyncGenerators","objectRestSpread","objectRestSpread"],"allowImportExportEverywhere":true,"allowReturnOutsideFunction":true,"allowUndeclaredExports":true,"strictMode":false},"caller":{"name":"meteor","arch":"os.windows.x86_64"},"sourceFileName":"packages/cfs:tempstore/tempStore.js","filename":"C:\\Users\\Haseeb\\Desktop\\Aangan-main\\Aangan-main\\packages\\cfs:tempstore\\tempStore.js","targets":{},"cloneInputAst":true,"browserslistConfigFile":false,"passPerPreset":false,"envName":"development","cwd":"C:\\Users\\Haseeb\\Desktop\\Aangan-main\\Aangan-main","root":"C:\\Users\\Haseeb\\Desktop\\Aangan-main\\Aangan-main","rootMode":"root","plugins":[{"key":"base$0","visitor":{"_exploded":true,"_verified":true},"options":{}},{"key":"base$0$0","visitor":{"Program":{"enter":[null],"exit":[null]},"_exploded":true,"_verified":true},"options":{"avoidModernSyntax":false,"enforceStrictMode":false,"dynamicImport":true,"generateLetDeclarations":true}},{"key":"transform-runtime","visitor":{"MemberExpression":{"enter":[null]},"ObjectPattern":{"enter":[null]},"BinaryExpression":{"enter":[null]},"_exploded":{},"_verified":{},"Identifier":{"enter":[null]},"JSXIdentifier":{"enter":[null]}},"options":{"version":"7.13.10","helpers":true,"useESModules":false,"corejs":false}},{"key":"syntax-object-rest-spread","visitor":{"_exploded":true,"_verified":true},"options":{}},{"key":"proposal-object-rest-spread","visitor":{"_exploded":{},"_verified":{},"VariableDeclarator":{"enter":[null]},"ExportNamedDeclaration":{"enter":[null]},"CatchClause":{"enter":[null]},"AssignmentExpression":{"enter":[null]},"ArrayPattern":{"enter":[null]},"ObjectExpression":{"enter":[null]},"FunctionDeclaration":{"enter":[null]},"FunctionExpression":{"enter":[null]},"ObjectMethod":{"enter":[null]},"ArrowFunctionExpression":{"enter":[null]},"ClassMethod":{"enter":[null]},"ClassPrivateMethod":{"enter":[null]},"ForInStatement":{"enter":[null]},"ForOfStatement":{"enter":[null]}},"options":{}},{"key":"transform-meteor-async-await","visitor":{"AwaitExpression":{"enter":[null]},"_exploded":true,"_verified":true,"FunctionDeclaration":{"exit":[null]},"FunctionExpression":{"exit":[null]},"ObjectMethod":{"exit":[null]},"ArrowFunctionExpression":{"exit":[null]},"ClassMethod":{"exit":[null]},"ClassPrivateMethod":{"exit":[null]}},"options":{"useNativeAsyncAwait":false}},{"key":"proposal-async-generator-functions","visitor":{"_exploded":{},"_verified":{},"Program":{"enter":[null]}},"options":{}},{"key":"proposal-class-properties","visitor":{"PrivateName":{"enter":[null]},"ExportDefaultDeclaration":{"enter":[null]},"_exploded":true,"_verified":true,"ClassExpression":{"enter":[null]},"ClassDeclaration":{"enter":[null]}},"options":{"loose":true}},{"key":"transform-react-jsx","visitor":{"_exploded":{},"_verified":{},"JSXNamespacedName":{"enter":[null]},"JSXSpreadChild":{"enter":[null]},"Program":{"enter":[null]},"JSXElement":{"exit":[null]},"JSXFragment":{"exit":[null]},"JSXAttribute":{"enter":[null]}},"options":{"pragma":"React.createElement","pragmaFrag":"React.Fragment","runtime":"classic","throwIfNamespace":true,"useBuiltIns":false}},{"key":"transform-react-display-name","visitor":{"ExportDefaultDeclaration":{"enter":[null]},"CallExpression":{"enter":[null]},"_exploded":true,"_verified":true},"options":{}},{"key":"transform-react-pure-annotations","visitor":{"CallExpression":{"enter":[null]},"_exploded":true,"_verified":true},"options":{}},{"key":"syntax-nullish-coalescing-operator","visitor":{"_exploded":true,"_verified":true},"options":{}},{"key":"proposal-nullish-coalescing-operator","visitor":{"_exploded":{},"_verified":{},"LogicalExpression":{"enter":[null]}},"options":{}},{"key":"syntax-optional-chaining","visitor":{"_exploded":true,"_verified":true},"options":{}},{"key":"proposal-optional-chaining","visitor":{"_exploded":{},"_verified":{},"OptionalCallExpression":{"enter":[null]},"OptionalMemberExpression":{"enter":[null]}},"options":{}},{"key":"syntax-optional-catch-binding","visitor":{"_exploded":true,"_verified":true},"options":{}},{"key":"proposal-optional-catch-binding","visitor":{"_exploded":{},"_verified":{},"CatchClause":{"enter":[null]}},"options":{}},{"key":"syntax-class-properties","visitor":{"_exploded":true,"_verified":true},"options":{}},{"key":"proposal-class-properties","visitor":{"PrivateName":{"enter":[null]},"ExportDefaultDeclaration":{"enter":[null]},"_exploded":true,"_verified":true,"ClassExpression":{"enter":[null]},"ClassDeclaration":{"enter":[null]}},"options":{}},{"key":"syntax-async-generators","visitor":{"_exploded":true,"_verified":true},"options":{}},{"key":"proposal-async-generator-functions","visitor":{"_exploded":{},"_verified":{},"Program":{"enter":[null]}},"options":{}},{"key":"syntax-object-rest-spread","visitor":{"_exploded":true,"_verified":true},"options":{}},{"key":"proposal-object-rest-spread","visitor":{"_exploded":{},"_verified":{},"VariableDeclarator":{"enter":[null]},"ExportNamedDeclaration":{"enter":[null]},"CatchClause":{"enter":[null]},"AssignmentExpression":{"enter":[null]},"ArrayPattern":{"enter":[null]},"ObjectExpression":{"enter":[null]},"FunctionDeclaration":{"enter":[null]},"FunctionExpression":{"enter":[null]},"ObjectMethod":{"enter":[null]},"ArrowFunctionExpression":{"enter":[null]},"ClassMethod":{"enter":[null]},"ClassPrivateMethod":{"enter":[null]},"ForInStatement":{"enter":[null]},"ForOfStatement":{"enter":[null]}},"options":{}},{"key":"transform-literals","visitor":{"NumericLiteral":{"enter":[null]},"StringLiteral":{"enter":[null]},"_exploded":true,"_verified":true},"options":{}},{"key":"transform-template-literals","visitor":{"TaggedTemplateExpression":{"enter":[null]},"TemplateLiteral":{"enter":[null]},"_exploded":true,"_verified":true},"options":{}},{"key":"transform-parameters","visitor":{"_exploded":true,"_verified":true,"FunctionDeclaration":{"enter":[null]},"FunctionExpression":{"enter":[null]},"ObjectMethod":{"enter":[null]},"ArrowFunctionExpression":{"enter":[null]},"ClassMethod":{"enter":[null]},"ClassPrivateMethod":{"enter":[null]}},"options":{}},{"key":"transform-exponentiation-operator","visitor":{"AssignmentExpression":{"enter":[null]},"BinaryExpression":{"enter":[null]},"_exploded":true,"_verified":true},"options":{}}],"presets":[],"generatorOpts":{"filename":"C:\\Users\\Haseeb\\Desktop\\Aangan-main\\Aangan-main\\packages\\cfs:tempstore\\tempStore.js","comments":true,"compact":false,"sourceMaps":true,"sourceFileName":"packages/cfs:tempstore/tempStore.js"}},"code":"// ##Temporary Storage\n//\n// Temporary storage is used for chunked uploads until all chunks are received\n// and all copies have been made or given up. In some cases, the original file\n// is stored only in temporary storage (for example, if all copies do some\n// manipulation in beforeSave). This is why we use the temporary file as the\n// basis for each saved copy, and then remove it after all copies are saved.\n//\n// Every chunk is saved as an individual temporary file. This is safer than\n// attempting to write multiple incoming chunks to different positions in a\n// single temporary file, which can lead to write conflicts.\n//\n// Using temp files also allows us to easily resume uploads, even if the server\n// restarts, and to keep the working memory clear.\n// The FS.TempStore emits events that others are able to listen to\nvar EventEmitter = Npm.require('events').EventEmitter; // We have a special stream concating all chunk files into one readable stream\n\n\nvar CombinedStream = Npm.require('combined-stream');\n/** @namespace FS.TempStore\n * @property FS.TempStore\n * @type {object}\n * @public\n * @summary An event emitter\n */\n\n\nFS.TempStore = new EventEmitter(); // Create a tracker collection for keeping track of all chunks for any files that are currently in the temp store\n\nvar tracker = FS.TempStore.Tracker = new Mongo.Collection('cfs._tempstore.chunks');\n/**\n * @property FS.TempStore.Storage\n * @type {StorageAdapter}\n * @namespace FS.TempStore\n * @private\n * @summary This property is set to either `FS.Store.FileSystem` or `FS.Store.GridFS`\n *\n * __When and why:__\n * We normally default to `cfs-filesystem` unless its not installed. *(we default to gridfs if installed)*\n * But if `cfs-gridfs` and `cfs-worker` is installed we default to `cfs-gridfs`\n *\n * If `cfs-gridfs` and `cfs-filesystem` is not installed we log a warning.\n * the user can set `FS.TempStore.Storage` them selfs eg.:\n * ```js\n *   // Its important to set `internal: true` this lets the SA know that we\n *   // are using this internally and it will give us direct SA api\n *   FS.TempStore.Storage = new FS.Store.GridFS('_tempstore', { internal: true });\n * ```\n *\n * > Note: This is considered as `advanced` use, its not a common pattern.\n */\n\nFS.TempStore.Storage = null; // We will not mount a storage adapter until needed. This allows us to check for the\n// existance of FS.FileWorker, which is loaded after this package because it\n// depends on this package.\n\nfunction mountStorage() {\n  if (FS.TempStore.Storage) return; // XXX: We could replace this test, testing the FS scope for grifFS etc.\n  // This is on the todo later when we get \"stable\"\n\n  if (Package[\"cfs:gridfs\"] && (Package[\"cfs:worker\"] || !Package[\"cfs:filesystem\"])) {\n    // If the file worker is installed we would prefer to use the gridfs sa\n    // for scalability. We also default to gridfs if filesystem is not found\n    // Use the gridfs\n    FS.TempStore.Storage = new FS.Store.GridFS('_tempstore', {\n      internal: true\n    });\n  } else if (Package[\"cfs:filesystem\"]) {\n    // use the Filesystem\n    FS.TempStore.Storage = new FS.Store.FileSystem('_tempstore', {\n      internal: true\n    });\n  } else {\n    throw new Error('FS.TempStore.Storage is not set: Install cfs:filesystem or cfs:gridfs or set it manually');\n  }\n\n  FS.debug && console.log('TempStore is mounted on', FS.TempStore.Storage.typeName);\n}\n\nfunction mountFile(fileObj, name) {\n  if (!fileObj.isMounted()) {\n    throw new Error(name + ' cannot work with unmounted file');\n  }\n} // We update the fileObj on progress\n\n\nFS.TempStore.on('progress', function (fileObj, chunkNum, count, total, result) {\n  FS.debug && console.log('TempStore progress: Received ' + count + ' of ' + total + ' chunks for ' + fileObj.name());\n}); // XXX: TODO\n// FS.TempStore.on('stored', function(fileObj, chunkCount, result) {\n//   // This should work if we pass on result from the SA on stored event...\n//   fileObj.update({ $set: { chunkSum: 1, chunkCount: chunkCount, size: result.size } });\n// });\n// Stream implementation\n\n/**\n * @method _chunkPath\n * @private\n * @param {Number} [n] Chunk number\n * @returns {String} Chunk naming convention\n */\n\n_chunkPath = function (n) {\n  return (n || 0) + '.chunk';\n};\n/**\n * @method _fileReference\n * @param {FS.File} fileObj\n * @param {Number} chunk\n * @private\n * @returns {String} Generated SA specific fileKey for the chunk\n *\n * Note: Calling function should call mountStorage() first, and\n * make sure that fileObj is mounted.\n */\n\n\n_fileReference = function (fileObj, chunk, existing) {\n  // Maybe it's a chunk we've already saved\n  existing = existing || tracker.findOne({\n    fileId: fileObj._id,\n    collectionName: fileObj.collectionName\n  }); // Make a temporary fileObj just for fileKey generation\n\n  var tempFileObj = new FS.File({\n    collectionName: fileObj.collectionName,\n    _id: fileObj._id,\n    original: {\n      name: _chunkPath(chunk)\n    },\n    copies: {\n      _tempstore: {\n        key: existing && existing.keys[chunk]\n      }\n    }\n  }); // Return a fitting fileKey SA specific\n\n  return FS.TempStore.Storage.adapter.fileKey(tempFileObj);\n};\n/**\n * @method FS.TempStore.exists\n * @param {FS.File} File object\n * @returns {Boolean} Is this file, or parts of it, currently stored in the TempStore\n */\n\n\nFS.TempStore.exists = function (fileObj) {\n  var existing = tracker.findOne({\n    fileId: fileObj._id,\n    collectionName: fileObj.collectionName\n  });\n  return !!existing;\n};\n/**\n * @method FS.TempStore.listParts\n * @param {FS.File} fileObj\n * @returns {Object} of parts already stored\n * @todo This is not yet implemented, milestone 1.1.0\n */\n\n\nFS.TempStore.listParts = function fsTempStoreListParts(fileObj) {\n  var self = this;\n  console.warn('This function is not correctly implemented using SA in TempStore'); //XXX This function might be necessary for resume. Not currently supported.\n};\n/**\n * @method FS.TempStore.removeFile\n * @public\n * @param {FS.File} fileObj\n * This function removes the file from tempstorage - it cares not if file is\n * already removed or not found, goal is reached anyway.\n */\n\n\nFS.TempStore.removeFile = function fsTempStoreRemoveFile(fileObj) {\n  var self = this; // Ensure that we have a storage adapter mounted; if not, throw an error.\n\n  mountStorage(); // If fileObj is not mounted or can't be, throw an error\n\n  mountFile(fileObj, 'FS.TempStore.removeFile'); // Emit event\n\n  self.emit('remove', fileObj);\n  var chunkInfo = tracker.findOne({\n    fileId: fileObj._id,\n    collectionName: fileObj.collectionName\n  });\n\n  if (chunkInfo) {\n    // Unlink each file\n    FS.Utility.each(chunkInfo.keys || {}, function (key, chunk) {\n      var fileKey = _fileReference(fileObj, chunk, chunkInfo);\n\n      FS.TempStore.Storage.adapter.remove(fileKey, FS.Utility.noop);\n    }); // Remove fileObj from tracker collection, too\n\n    tracker.remove({\n      _id: chunkInfo._id\n    });\n  }\n};\n/**\n * @method FS.TempStore.removeAll\n * @public\n * @summary This function removes all files from tempstorage - it cares not if file is\n * already removed or not found, goal is reached anyway.\n */\n\n\nFS.TempStore.removeAll = function fsTempStoreRemoveAll() {\n  var self = this; // Ensure that we have a storage adapter mounted; if not, throw an error.\n\n  mountStorage();\n  tracker.find().forEach(function (chunkInfo) {\n    // Unlink each file\n    FS.Utility.each(chunkInfo.keys || {}, function (key, chunk) {\n      var fileKey = _fileReference({\n        _id: chunkInfo.fileId,\n        collectionName: chunkInfo.collectionName\n      }, chunk, chunkInfo);\n\n      FS.TempStore.Storage.adapter.remove(fileKey, FS.Utility.noop);\n    }); // Remove from tracker collection, too\n\n    tracker.remove({\n      _id: chunkInfo._id\n    });\n  });\n};\n/**\n * @method FS.TempStore.createWriteStream\n * @public\n * @param {FS.File} fileObj File to store in temporary storage\n * @param {Number | String} [options]\n * @returns {Stream} Writeable stream\n *\n * `options` of different types mean differnt things:\n * * `undefined` We store the file in one part\n * *(Normal server-side api usage)*\n * * `Number` the number is the part number total\n * *(multipart uploads will use this api)*\n * * `String` the string is the name of the `store` that wants to store file data\n * *(stores that want to sync their data to the rest of the files stores will use this)*\n *\n * > Note: fileObj must be mounted on a `FS.Collection`, it makes no sense to store otherwise\n */\n\n\nFS.TempStore.createWriteStream = function (fileObj, options) {\n  var self = this; // Ensure that we have a storage adapter mounted; if not, throw an error.\n\n  mountStorage(); // If fileObj is not mounted or can't be, throw an error\n\n  mountFile(fileObj, 'FS.TempStore.createWriteStream'); // Cache the selector for use multiple times below\n\n  var selector = {\n    fileId: fileObj._id,\n    collectionName: fileObj.collectionName\n  }; // TODO, should pass in chunkSum so we don't need to use FS.File for it\n\n  var chunkSum = fileObj.chunkSum || 1; // Add fileObj to tracker collection\n\n  tracker.upsert(selector, {\n    $setOnInsert: {\n      keys: {}\n    }\n  }); // Determine how we're using the writeStream\n\n  var isOnePart = false,\n      isMultiPart = false,\n      isStoreSync = false,\n      chunkNum = 0;\n\n  if (options === +options) {\n    isMultiPart = true;\n    chunkNum = options;\n  } else if (options === '' + options) {\n    isStoreSync = true;\n  } else {\n    isOnePart = true;\n  } // XXX: it should be possible for a store to sync by storing data into the\n  // tempstore - this could be done nicely by setting the store name as string\n  // in the chunk variable?\n  // This store name could be passed on the the fileworker via the uploaded\n  // event\n  // So the uploaded event can return:\n  // undefined - if data is stored into and should sync out to all storage adapters\n  // number - if a chunk has been uploaded\n  // string - if a storage adapter wants to sync its data to the other SA's\n  // Find a nice location for the chunk data\n\n\n  var fileKey = _fileReference(fileObj, chunkNum); // Create the stream as Meteor safe stream\n\n\n  var writeStream = FS.TempStore.Storage.adapter.createWriteStream(fileKey); // When the stream closes we update the chunkCount\n\n  writeStream.safeOn('stored', function (result) {\n    // Save key in tracker document\n    var setObj = {};\n    setObj['keys.' + chunkNum] = result.fileKey;\n    tracker.update(selector, {\n      $set: setObj\n    });\n    var temp = tracker.findOne(selector);\n\n    if (!temp) {\n      FS.debug && console.log('NOT FOUND FROM TEMPSTORE => EXIT (REMOVED)');\n      return;\n    } // Get updated chunkCount\n\n\n    var chunkCount = FS.Utility.size(temp.keys); // Progress\n\n    self.emit('progress', fileObj, chunkNum, chunkCount, chunkSum, result);\n    var modifier = {\n      $set: {}\n    };\n\n    if (!fileObj.instance_id) {\n      modifier.$set.instance_id = process.env.COLLECTIONFS_ENV_NAME_UNIQUE_ID ? process.env[process.env.COLLECTIONFS_ENV_NAME_UNIQUE_ID] : process.env.METEOR_PARENT_PID;\n    } // If upload is completed\n\n\n    if (chunkCount === chunkSum) {\n      // We no longer need the chunk info\n      modifier.$unset = {\n        chunkCount: 1,\n        chunkSum: 1,\n        chunkSize: 1\n      }; // Check if the file has been uploaded before\n\n      if (typeof fileObj.uploadedAt === 'undefined') {\n        // We set the uploadedAt date\n        modifier.$set.uploadedAt = new Date();\n      } else {\n        // We have been uploaded so an event were file data is updated is\n        // called synchronizing - so this must be a synchronizedAt?\n        modifier.$set.synchronizedAt = new Date();\n      } // Update the fileObject\n\n\n      fileObj.update(modifier); // Fire ending events\n\n      var eventName = isStoreSync ? 'synchronized' : 'stored';\n      self.emit(eventName, fileObj, result); // XXX is emitting \"ready\" necessary?\n\n      self.emit('ready', fileObj, chunkCount, result);\n    } else {\n      // Update the chunkCount on the fileObject\n      modifier.$set.chunkCount = chunkCount;\n      fileObj.update(modifier);\n    }\n  }); // Emit errors\n\n  writeStream.on('error', function (error) {\n    FS.debug && console.log('TempStore writeStream error:', error);\n    self.emit('error', error, fileObj);\n  });\n  return writeStream;\n};\n/**\n  * @method FS.TempStore.createReadStream\n  * @public\n  * @param {FS.File} fileObj The file to read\n  * @return {Stream} Returns readable stream\n  *\n  */\n\n\nFS.TempStore.createReadStream = function (fileObj) {\n  // Ensure that we have a storage adapter mounted; if not, throw an error.\n  mountStorage(); // If fileObj is not mounted or can't be, throw an error\n\n  mountFile(fileObj, 'FS.TempStore.createReadStream');\n  FS.debug && console.log('FS.TempStore creating read stream for ' + fileObj._id); // Determine how many total chunks there are from the tracker collection\n\n  var chunkInfo = tracker.findOne({\n    fileId: fileObj._id,\n    collectionName: fileObj.collectionName\n  }) || {};\n  var totalChunks = FS.Utility.size(chunkInfo.keys);\n\n  function getNextStreamFunc(chunk) {\n    return Meteor.bindEnvironment(function (next) {\n      var fileKey = _fileReference(fileObj, chunk);\n\n      var chunkReadStream = FS.TempStore.Storage.adapter.createReadStream(fileKey);\n      next(chunkReadStream);\n    }, function (error) {\n      throw error;\n    });\n  } // Make a combined stream\n\n\n  var combinedStream = CombinedStream.create(); // Add each chunk stream to the combined stream when the previous chunk stream ends\n\n  var currentChunk = 0;\n\n  for (var chunk = 0; chunk < totalChunks; chunk++) {\n    combinedStream.append(getNextStreamFunc(chunk));\n  } // Return the combined stream\n\n\n  return combinedStream;\n};","map":{"version":3,"sources":["packages/cfs:tempstore/tempStore.js"],"names":["EventEmitter","Npm","require","CombinedStream","FS","TempStore","tracker","Tracker","Mongo","Collection","Storage","mountStorage","Package","Store","GridFS","internal","FileSystem","Error","debug","console","log","typeName","mountFile","fileObj","name","isMounted","on","chunkNum","count","total","result","_chunkPath","n","_fileReference","chunk","existing","findOne","fileId","_id","collectionName","tempFileObj","File","original","copies","_tempstore","key","keys","adapter","fileKey","exists","listParts","fsTempStoreListParts","self","warn","removeFile","fsTempStoreRemoveFile","emit","chunkInfo","Utility","each","remove","noop","removeAll","fsTempStoreRemoveAll","find","forEach","createWriteStream","options","selector","chunkSum","upsert","$setOnInsert","isOnePart","isMultiPart","isStoreSync","writeStream","safeOn","setObj","update","$set","temp","chunkCount","size","modifier","instance_id","process","env","COLLECTIONFS_ENV_NAME_UNIQUE_ID","METEOR_PARENT_PID","$unset","chunkSize","uploadedAt","Date","synchronizedAt","eventName","error","createReadStream","totalChunks","getNextStreamFunc","Meteor","bindEnvironment","next","chunkReadStream","combinedStream","create","currentChunk","append"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA,IAAIA,YAAY,GAAGC,GAAG,CAACC,OAAJ,CAAY,QAAZ,EAAsBF,YAAzC,C,CAEA;;;AACA,IAAIG,cAAc,GAAGF,GAAG,CAACC,OAAJ,CAAY,iBAAZ,CAArB;AAEA;AACA;AACA;AACA;AACA;AACA;;;AACAE,EAAE,CAACC,SAAH,GAAe,IAAIL,YAAJ,EAAf,C,CAEA;;AACA,IAAIM,OAAO,GAAGF,EAAE,CAACC,SAAH,CAAaE,OAAb,GAAuB,IAAIC,KAAK,CAACC,UAAV,CAAqB,uBAArB,CAArC;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACAL,EAAE,CAACC,SAAH,CAAaK,OAAb,GAAuB,IAAvB,C,CAEA;AACA;AACA;;AACA,SAASC,YAAT,GAAwB;AAEtB,MAAIP,EAAE,CAACC,SAAH,CAAaK,OAAjB,EAA0B,OAFJ,CAItB;AACA;;AACA,MAAIE,OAAO,CAAC,YAAD,CAAP,KAA0BA,OAAO,CAAC,YAAD,CAAP,IAAyB,CAACA,OAAO,CAAC,gBAAD,CAA3D,CAAJ,EAAoF;AAClF;AACA;AAEA;AACAR,IAAAA,EAAE,CAACC,SAAH,CAAaK,OAAb,GAAuB,IAAIN,EAAE,CAACS,KAAH,CAASC,MAAb,CAAoB,YAApB,EAAkC;AAAEC,MAAAA,QAAQ,EAAE;AAAZ,KAAlC,CAAvB;AACD,GAND,MAMO,IAAIH,OAAO,CAAC,gBAAD,CAAX,EAA+B;AAEpC;AACAR,IAAAA,EAAE,CAACC,SAAH,CAAaK,OAAb,GAAuB,IAAIN,EAAE,CAACS,KAAH,CAASG,UAAb,CAAwB,YAAxB,EAAsC;AAAED,MAAAA,QAAQ,EAAE;AAAZ,KAAtC,CAAvB;AACD,GAJM,MAIA;AACL,UAAM,IAAIE,KAAJ,CAAU,0FAAV,CAAN;AACD;;AAEDb,EAAAA,EAAE,CAACc,KAAH,IAAYC,OAAO,CAACC,GAAR,CAAY,yBAAZ,EAAuChB,EAAE,CAACC,SAAH,CAAaK,OAAb,CAAqBW,QAA5D,CAAZ;AACD;;AAED,SAASC,SAAT,CAAmBC,OAAnB,EAA4BC,IAA5B,EAAkC;AAChC,MAAI,CAACD,OAAO,CAACE,SAAR,EAAL,EAA0B;AACxB,UAAM,IAAIR,KAAJ,CAAUO,IAAI,GAAG,kCAAjB,CAAN;AACD;AACF,C,CAED;;;AACApB,EAAE,CAACC,SAAH,CAAaqB,EAAb,CAAgB,UAAhB,EAA4B,UAASH,OAAT,EAAkBI,QAAlB,EAA4BC,KAA5B,EAAmCC,KAAnC,EAA0CC,MAA1C,EAAkD;AAC5E1B,EAAAA,EAAE,CAACc,KAAH,IAAYC,OAAO,CAACC,GAAR,CAAY,kCAAkCQ,KAAlC,GAA0C,MAA1C,GAAmDC,KAAnD,GAA2D,cAA3D,GAA4EN,OAAO,CAACC,IAAR,EAAxF,CAAZ;AACD,CAFD,E,CAIA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AACAO,UAAU,GAAG,UAASC,CAAT,EAAY;AACvB,SAAO,CAACA,CAAC,IAAI,CAAN,IAAW,QAAlB;AACD,CAFD;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACAC,cAAc,GAAG,UAASV,OAAT,EAAkBW,KAAlB,EAAyBC,QAAzB,EAAmC;AAClD;AACAA,EAAAA,QAAQ,GAAGA,QAAQ,IAAI7B,OAAO,CAAC8B,OAAR,CAAgB;AAACC,IAAAA,MAAM,EAAEd,OAAO,CAACe,GAAjB;AAAsBC,IAAAA,cAAc,EAAEhB,OAAO,CAACgB;AAA9C,GAAhB,CAAvB,CAFkD,CAIlD;;AACA,MAAIC,WAAW,GAAG,IAAIpC,EAAE,CAACqC,IAAP,CAAY;AAC5BF,IAAAA,cAAc,EAAEhB,OAAO,CAACgB,cADI;AAE5BD,IAAAA,GAAG,EAAEf,OAAO,CAACe,GAFe;AAG5BI,IAAAA,QAAQ,EAAE;AACRlB,MAAAA,IAAI,EAAEO,UAAU,CAACG,KAAD;AADR,KAHkB;AAM5BS,IAAAA,MAAM,EAAE;AACNC,MAAAA,UAAU,EAAE;AACVC,QAAAA,GAAG,EAAEV,QAAQ,IAAIA,QAAQ,CAACW,IAAT,CAAcZ,KAAd;AADP;AADN;AANoB,GAAZ,CAAlB,CALkD,CAkBlD;;AACA,SAAO9B,EAAE,CAACC,SAAH,CAAaK,OAAb,CAAqBqC,OAArB,CAA6BC,OAA7B,CAAqCR,WAArC,CAAP;AACD,CApBD;AAsBA;AACA;AACA;AACA;AACA;;;AACApC,EAAE,CAACC,SAAH,CAAa4C,MAAb,GAAsB,UAAS1B,OAAT,EAAkB;AACtC,MAAIY,QAAQ,GAAG7B,OAAO,CAAC8B,OAAR,CAAgB;AAACC,IAAAA,MAAM,EAAEd,OAAO,CAACe,GAAjB;AAAsBC,IAAAA,cAAc,EAAEhB,OAAO,CAACgB;AAA9C,GAAhB,CAAf;AACA,SAAO,CAAC,CAACJ,QAAT;AACD,CAHD;AAKA;AACA;AACA;AACA;AACA;AACA;;;AACA/B,EAAE,CAACC,SAAH,CAAa6C,SAAb,GAAyB,SAASC,oBAAT,CAA8B5B,OAA9B,EAAuC;AAC9D,MAAI6B,IAAI,GAAG,IAAX;AACAjC,EAAAA,OAAO,CAACkC,IAAR,CAAa,kEAAb,EAF8D,CAG9D;AACD,CAJD;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACAjD,EAAE,CAACC,SAAH,CAAaiD,UAAb,GAA0B,SAASC,qBAAT,CAA+BhC,OAA/B,EAAwC;AAChE,MAAI6B,IAAI,GAAG,IAAX,CADgE,CAGhE;;AACAzC,EAAAA,YAAY,GAJoD,CAMhE;;AACAW,EAAAA,SAAS,CAACC,OAAD,EAAU,yBAAV,CAAT,CAPgE,CAShE;;AACA6B,EAAAA,IAAI,CAACI,IAAL,CAAU,QAAV,EAAoBjC,OAApB;AAEA,MAAIkC,SAAS,GAAGnD,OAAO,CAAC8B,OAAR,CAAgB;AAC9BC,IAAAA,MAAM,EAAEd,OAAO,CAACe,GADc;AAE9BC,IAAAA,cAAc,EAAEhB,OAAO,CAACgB;AAFM,GAAhB,CAAhB;;AAKA,MAAIkB,SAAJ,EAAe;AAEb;AACArD,IAAAA,EAAE,CAACsD,OAAH,CAAWC,IAAX,CAAgBF,SAAS,CAACX,IAAV,IAAkB,EAAlC,EAAsC,UAAUD,GAAV,EAAeX,KAAf,EAAsB;AAC1D,UAAIc,OAAO,GAAGf,cAAc,CAACV,OAAD,EAAUW,KAAV,EAAiBuB,SAAjB,CAA5B;;AACArD,MAAAA,EAAE,CAACC,SAAH,CAAaK,OAAb,CAAqBqC,OAArB,CAA6Ba,MAA7B,CAAoCZ,OAApC,EAA6C5C,EAAE,CAACsD,OAAH,CAAWG,IAAxD;AACD,KAHD,EAHa,CAQb;;AACAvD,IAAAA,OAAO,CAACsD,MAAR,CAAe;AAACtB,MAAAA,GAAG,EAAEmB,SAAS,CAACnB;AAAhB,KAAf;AAED;AACF,CA7BD;AA+BA;AACA;AACA;AACA;AACA;AACA;;;AACAlC,EAAE,CAACC,SAAH,CAAayD,SAAb,GAAyB,SAASC,oBAAT,GAAgC;AACvD,MAAIX,IAAI,GAAG,IAAX,CADuD,CAGvD;;AACAzC,EAAAA,YAAY;AAEZL,EAAAA,OAAO,CAAC0D,IAAR,GAAeC,OAAf,CAAuB,UAAUR,SAAV,EAAqB;AAC1C;AACArD,IAAAA,EAAE,CAACsD,OAAH,CAAWC,IAAX,CAAgBF,SAAS,CAACX,IAAV,IAAkB,EAAlC,EAAsC,UAAUD,GAAV,EAAeX,KAAf,EAAsB;AAC1D,UAAIc,OAAO,GAAGf,cAAc,CAAC;AAACK,QAAAA,GAAG,EAAEmB,SAAS,CAACpB,MAAhB;AAAwBE,QAAAA,cAAc,EAAEkB,SAAS,CAAClB;AAAlD,OAAD,EAAoEL,KAApE,EAA2EuB,SAA3E,CAA5B;;AACArD,MAAAA,EAAE,CAACC,SAAH,CAAaK,OAAb,CAAqBqC,OAArB,CAA6Ba,MAA7B,CAAoCZ,OAApC,EAA6C5C,EAAE,CAACsD,OAAH,CAAWG,IAAxD;AACD,KAHD,EAF0C,CAO1C;;AACAvD,IAAAA,OAAO,CAACsD,MAAR,CAAe;AAACtB,MAAAA,GAAG,EAAEmB,SAAS,CAACnB;AAAhB,KAAf;AACD,GATD;AAUD,CAhBD;AAkBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACAlC,EAAE,CAACC,SAAH,CAAa6D,iBAAb,GAAiC,UAAS3C,OAAT,EAAkB4C,OAAlB,EAA2B;AAC1D,MAAIf,IAAI,GAAG,IAAX,CAD0D,CAG1D;;AACAzC,EAAAA,YAAY,GAJ8C,CAM1D;;AACAW,EAAAA,SAAS,CAACC,OAAD,EAAU,gCAAV,CAAT,CAP0D,CAS1D;;AACA,MAAI6C,QAAQ,GAAG;AAAC/B,IAAAA,MAAM,EAAEd,OAAO,CAACe,GAAjB;AAAsBC,IAAAA,cAAc,EAAEhB,OAAO,CAACgB;AAA9C,GAAf,CAV0D,CAY1D;;AACA,MAAI8B,QAAQ,GAAG9C,OAAO,CAAC8C,QAAR,IAAoB,CAAnC,CAb0D,CAe1D;;AACA/D,EAAAA,OAAO,CAACgE,MAAR,CAAeF,QAAf,EAAyB;AAACG,IAAAA,YAAY,EAAE;AAACzB,MAAAA,IAAI,EAAE;AAAP;AAAf,GAAzB,EAhB0D,CAkB1D;;AACA,MAAI0B,SAAS,GAAG,KAAhB;AAAA,MAAuBC,WAAW,GAAG,KAArC;AAAA,MAA4CC,WAAW,GAAG,KAA1D;AAAA,MAAiE/C,QAAQ,GAAG,CAA5E;;AACA,MAAIwC,OAAO,KAAK,CAACA,OAAjB,EAA0B;AACxBM,IAAAA,WAAW,GAAG,IAAd;AACA9C,IAAAA,QAAQ,GAAGwC,OAAX;AACD,GAHD,MAGO,IAAIA,OAAO,KAAK,KAAGA,OAAnB,EAA4B;AACjCO,IAAAA,WAAW,GAAG,IAAd;AACD,GAFM,MAEA;AACLF,IAAAA,SAAS,GAAG,IAAZ;AACD,GA3ByD,CA6B1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;AACA,MAAIxB,OAAO,GAAGf,cAAc,CAACV,OAAD,EAAUI,QAAV,CAA5B,CAxC0D,CA0C1D;;;AACA,MAAIgD,WAAW,GAAGvE,EAAE,CAACC,SAAH,CAAaK,OAAb,CAAqBqC,OAArB,CAA6BmB,iBAA7B,CAA+ClB,OAA/C,CAAlB,CA3C0D,CA6C1D;;AACA2B,EAAAA,WAAW,CAACC,MAAZ,CAAmB,QAAnB,EAA6B,UAAS9C,MAAT,EAAiB;AAC5C;AACA,QAAI+C,MAAM,GAAG,EAAb;AACAA,IAAAA,MAAM,CAAC,UAAUlD,QAAX,CAAN,GAA6BG,MAAM,CAACkB,OAApC;AACA1C,IAAAA,OAAO,CAACwE,MAAR,CAAeV,QAAf,EAAyB;AAACW,MAAAA,IAAI,EAAEF;AAAP,KAAzB;AAEA,QAAIG,IAAI,GAAG1E,OAAO,CAAC8B,OAAR,CAAgBgC,QAAhB,CAAX;;AAEA,QAAI,CAACY,IAAL,EAAW;AACT5E,MAAAA,EAAE,CAACc,KAAH,IAAYC,OAAO,CAACC,GAAR,CAAY,4CAAZ,CAAZ;AACA;AACD,KAX2C,CAa5C;;;AACA,QAAI6D,UAAU,GAAG7E,EAAE,CAACsD,OAAH,CAAWwB,IAAX,CAAgBF,IAAI,CAAClC,IAArB,CAAjB,CAd4C,CAgB5C;;AACAM,IAAAA,IAAI,CAACI,IAAL,CAAU,UAAV,EAAsBjC,OAAtB,EAA+BI,QAA/B,EAAyCsD,UAAzC,EAAqDZ,QAArD,EAA+DvC,MAA/D;AAEA,QAAIqD,QAAQ,GAAG;AAAEJ,MAAAA,IAAI,EAAE;AAAR,KAAf;;AACA,QAAI,CAACxD,OAAO,CAAC6D,WAAb,EAA0B;AACxBD,MAAAA,QAAQ,CAACJ,IAAT,CAAcK,WAAd,GAA4BC,OAAO,CAACC,GAAR,CAAYC,+BAAZ,GAA8CF,OAAO,CAACC,GAAR,CAAYD,OAAO,CAACC,GAAR,CAAYC,+BAAxB,CAA9C,GAAyGF,OAAO,CAACC,GAAR,CAAYE,iBAAjJ;AACD,KAtB2C,CAwB5C;;;AACA,QAAIP,UAAU,KAAKZ,QAAnB,EAA6B;AAC3B;AACAc,MAAAA,QAAQ,CAACM,MAAT,GAAkB;AAACR,QAAAA,UAAU,EAAE,CAAb;AAAgBZ,QAAAA,QAAQ,EAAE,CAA1B;AAA6BqB,QAAAA,SAAS,EAAE;AAAxC,OAAlB,CAF2B,CAI3B;;AACA,UAAI,OAAOnE,OAAO,CAACoE,UAAf,KAA8B,WAAlC,EAA+C;AAC7C;AACAR,QAAAA,QAAQ,CAACJ,IAAT,CAAcY,UAAd,GAA2B,IAAIC,IAAJ,EAA3B;AACD,OAHD,MAGO;AACL;AACA;AACAT,QAAAA,QAAQ,CAACJ,IAAT,CAAcc,cAAd,GAA+B,IAAID,IAAJ,EAA/B;AACD,OAZ0B,CAc3B;;;AACArE,MAAAA,OAAO,CAACuD,MAAR,CAAeK,QAAf,EAf2B,CAiB3B;;AACA,UAAIW,SAAS,GAAGpB,WAAW,GAAG,cAAH,GAAoB,QAA/C;AACAtB,MAAAA,IAAI,CAACI,IAAL,CAAUsC,SAAV,EAAqBvE,OAArB,EAA8BO,MAA9B,EAnB2B,CAqB3B;;AACAsB,MAAAA,IAAI,CAACI,IAAL,CAAU,OAAV,EAAmBjC,OAAnB,EAA4B0D,UAA5B,EAAwCnD,MAAxC;AACD,KAvBD,MAuBO;AACL;AACAqD,MAAAA,QAAQ,CAACJ,IAAT,CAAcE,UAAd,GAA2BA,UAA3B;AACA1D,MAAAA,OAAO,CAACuD,MAAR,CAAeK,QAAf;AACD;AACF,GArDD,EA9C0D,CAqG1D;;AACAR,EAAAA,WAAW,CAACjD,EAAZ,CAAe,OAAf,EAAwB,UAAUqE,KAAV,EAAiB;AACvC3F,IAAAA,EAAE,CAACc,KAAH,IAAYC,OAAO,CAACC,GAAR,CAAY,8BAAZ,EAA4C2E,KAA5C,CAAZ;AACA3C,IAAAA,IAAI,CAACI,IAAL,CAAU,OAAV,EAAmBuC,KAAnB,EAA0BxE,OAA1B;AACD,GAHD;AAKA,SAAOoD,WAAP;AACD,CA5GD;AA8GA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACAvE,EAAE,CAACC,SAAH,CAAa2F,gBAAb,GAAgC,UAASzE,OAAT,EAAkB;AAChD;AACAZ,EAAAA,YAAY,GAFoC,CAIhD;;AACAW,EAAAA,SAAS,CAACC,OAAD,EAAU,+BAAV,CAAT;AAEAnB,EAAAA,EAAE,CAACc,KAAH,IAAYC,OAAO,CAACC,GAAR,CAAY,2CAA2CG,OAAO,CAACe,GAA/D,CAAZ,CAPgD,CAShD;;AACA,MAAImB,SAAS,GAAGnD,OAAO,CAAC8B,OAAR,CAAgB;AAACC,IAAAA,MAAM,EAAEd,OAAO,CAACe,GAAjB;AAAsBC,IAAAA,cAAc,EAAEhB,OAAO,CAACgB;AAA9C,GAAhB,KAAkF,EAAlG;AACA,MAAI0D,WAAW,GAAG7F,EAAE,CAACsD,OAAH,CAAWwB,IAAX,CAAgBzB,SAAS,CAACX,IAA1B,CAAlB;;AAEA,WAASoD,iBAAT,CAA2BhE,KAA3B,EAAkC;AAChC,WAAOiE,MAAM,CAACC,eAAP,CAAuB,UAASC,IAAT,EAAe;AAC3C,UAAIrD,OAAO,GAAGf,cAAc,CAACV,OAAD,EAAUW,KAAV,CAA5B;;AACA,UAAIoE,eAAe,GAAGlG,EAAE,CAACC,SAAH,CAAaK,OAAb,CAAqBqC,OAArB,CAA6BiD,gBAA7B,CAA8ChD,OAA9C,CAAtB;AACAqD,MAAAA,IAAI,CAACC,eAAD,CAAJ;AACD,KAJM,EAIJ,UAAUP,KAAV,EAAiB;AAClB,YAAMA,KAAN;AACD,KANM,CAAP;AAOD,GArB+C,CAuBhD;;;AACA,MAAIQ,cAAc,GAAGpG,cAAc,CAACqG,MAAf,EAArB,CAxBgD,CA0BhD;;AACA,MAAIC,YAAY,GAAG,CAAnB;;AACA,OAAK,IAAIvE,KAAK,GAAG,CAAjB,EAAoBA,KAAK,GAAG+D,WAA5B,EAAyC/D,KAAK,EAA9C,EAAkD;AAChDqE,IAAAA,cAAc,CAACG,MAAf,CAAsBR,iBAAiB,CAAChE,KAAD,CAAvC;AACD,GA9B+C,CAgChD;;;AACA,SAAOqE,cAAP;AACD,CAlCD","sourcesContent":["// ##Temporary Storage\n//\n// Temporary storage is used for chunked uploads until all chunks are received\n// and all copies have been made or given up. In some cases, the original file\n// is stored only in temporary storage (for example, if all copies do some\n// manipulation in beforeSave). This is why we use the temporary file as the\n// basis for each saved copy, and then remove it after all copies are saved.\n//\n// Every chunk is saved as an individual temporary file. This is safer than\n// attempting to write multiple incoming chunks to different positions in a\n// single temporary file, which can lead to write conflicts.\n//\n// Using temp files also allows us to easily resume uploads, even if the server\n// restarts, and to keep the working memory clear.\n\n// The FS.TempStore emits events that others are able to listen to\nvar EventEmitter = Npm.require('events').EventEmitter;\n\n// We have a special stream concating all chunk files into one readable stream\nvar CombinedStream = Npm.require('combined-stream');\n\n/** @namespace FS.TempStore\n * @property FS.TempStore\n * @type {object}\n * @public\n * @summary An event emitter\n */\nFS.TempStore = new EventEmitter();\n\n// Create a tracker collection for keeping track of all chunks for any files that are currently in the temp store\nvar tracker = FS.TempStore.Tracker = new Mongo.Collection('cfs._tempstore.chunks');\n\n/**\n * @property FS.TempStore.Storage\n * @type {StorageAdapter}\n * @namespace FS.TempStore\n * @private\n * @summary This property is set to either `FS.Store.FileSystem` or `FS.Store.GridFS`\n *\n * __When and why:__\n * We normally default to `cfs-filesystem` unless its not installed. *(we default to gridfs if installed)*\n * But if `cfs-gridfs` and `cfs-worker` is installed we default to `cfs-gridfs`\n *\n * If `cfs-gridfs` and `cfs-filesystem` is not installed we log a warning.\n * the user can set `FS.TempStore.Storage` them selfs eg.:\n * ```js\n *   // Its important to set `internal: true` this lets the SA know that we\n *   // are using this internally and it will give us direct SA api\n *   FS.TempStore.Storage = new FS.Store.GridFS('_tempstore', { internal: true });\n * ```\n *\n * > Note: This is considered as `advanced` use, its not a common pattern.\n */\nFS.TempStore.Storage = null;\n\n// We will not mount a storage adapter until needed. This allows us to check for the\n// existance of FS.FileWorker, which is loaded after this package because it\n// depends on this package.\nfunction mountStorage() {\n\n  if (FS.TempStore.Storage) return;\n\n  // XXX: We could replace this test, testing the FS scope for grifFS etc.\n  // This is on the todo later when we get \"stable\"\n  if (Package[\"cfs:gridfs\"] && (Package[\"cfs:worker\"] || !Package[\"cfs:filesystem\"])) {\n    // If the file worker is installed we would prefer to use the gridfs sa\n    // for scalability. We also default to gridfs if filesystem is not found\n\n    // Use the gridfs\n    FS.TempStore.Storage = new FS.Store.GridFS('_tempstore', { internal: true });\n  } else if (Package[\"cfs:filesystem\"]) {\n\n    // use the Filesystem\n    FS.TempStore.Storage = new FS.Store.FileSystem('_tempstore', { internal: true });\n  } else {\n    throw new Error('FS.TempStore.Storage is not set: Install cfs:filesystem or cfs:gridfs or set it manually');\n  }\n\n  FS.debug && console.log('TempStore is mounted on', FS.TempStore.Storage.typeName);\n}\n\nfunction mountFile(fileObj, name) {\n  if (!fileObj.isMounted()) {\n    throw new Error(name + ' cannot work with unmounted file');\n  }\n}\n\n// We update the fileObj on progress\nFS.TempStore.on('progress', function(fileObj, chunkNum, count, total, result) {\n  FS.debug && console.log('TempStore progress: Received ' + count + ' of ' + total + ' chunks for ' + fileObj.name());\n});\n\n// XXX: TODO\n// FS.TempStore.on('stored', function(fileObj, chunkCount, result) {\n//   // This should work if we pass on result from the SA on stored event...\n//   fileObj.update({ $set: { chunkSum: 1, chunkCount: chunkCount, size: result.size } });\n// });\n\n// Stream implementation\n\n/**\n * @method _chunkPath\n * @private\n * @param {Number} [n] Chunk number\n * @returns {String} Chunk naming convention\n */\n_chunkPath = function(n) {\n  return (n || 0) + '.chunk';\n};\n\n/**\n * @method _fileReference\n * @param {FS.File} fileObj\n * @param {Number} chunk\n * @private\n * @returns {String} Generated SA specific fileKey for the chunk\n *\n * Note: Calling function should call mountStorage() first, and\n * make sure that fileObj is mounted.\n */\n_fileReference = function(fileObj, chunk, existing) {\n  // Maybe it's a chunk we've already saved\n  existing = existing || tracker.findOne({fileId: fileObj._id, collectionName: fileObj.collectionName});\n\n  // Make a temporary fileObj just for fileKey generation\n  var tempFileObj = new FS.File({\n    collectionName: fileObj.collectionName,\n    _id: fileObj._id,\n    original: {\n      name: _chunkPath(chunk)\n    },\n    copies: {\n      _tempstore: {\n        key: existing && existing.keys[chunk]\n      }\n    }\n  });\n\n  // Return a fitting fileKey SA specific\n  return FS.TempStore.Storage.adapter.fileKey(tempFileObj);\n};\n\n/**\n * @method FS.TempStore.exists\n * @param {FS.File} File object\n * @returns {Boolean} Is this file, or parts of it, currently stored in the TempStore\n */\nFS.TempStore.exists = function(fileObj) {\n  var existing = tracker.findOne({fileId: fileObj._id, collectionName: fileObj.collectionName});\n  return !!existing;\n};\n\n/**\n * @method FS.TempStore.listParts\n * @param {FS.File} fileObj\n * @returns {Object} of parts already stored\n * @todo This is not yet implemented, milestone 1.1.0\n */\nFS.TempStore.listParts = function fsTempStoreListParts(fileObj) {\n  var self = this;\n  console.warn('This function is not correctly implemented using SA in TempStore');\n  //XXX This function might be necessary for resume. Not currently supported.\n};\n\n/**\n * @method FS.TempStore.removeFile\n * @public\n * @param {FS.File} fileObj\n * This function removes the file from tempstorage - it cares not if file is\n * already removed or not found, goal is reached anyway.\n */\nFS.TempStore.removeFile = function fsTempStoreRemoveFile(fileObj) {\n  var self = this;\n\n  // Ensure that we have a storage adapter mounted; if not, throw an error.\n  mountStorage();\n\n  // If fileObj is not mounted or can't be, throw an error\n  mountFile(fileObj, 'FS.TempStore.removeFile');\n\n  // Emit event\n  self.emit('remove', fileObj);\n\n  var chunkInfo = tracker.findOne({\n    fileId: fileObj._id,\n    collectionName: fileObj.collectionName\n  });\n\n  if (chunkInfo) {\n\n    // Unlink each file\n    FS.Utility.each(chunkInfo.keys || {}, function (key, chunk) {\n      var fileKey = _fileReference(fileObj, chunk, chunkInfo);\n      FS.TempStore.Storage.adapter.remove(fileKey, FS.Utility.noop);\n    });\n\n    // Remove fileObj from tracker collection, too\n    tracker.remove({_id: chunkInfo._id});\n\n  }\n};\n\n/**\n * @method FS.TempStore.removeAll\n * @public\n * @summary This function removes all files from tempstorage - it cares not if file is\n * already removed or not found, goal is reached anyway.\n */\nFS.TempStore.removeAll = function fsTempStoreRemoveAll() {\n  var self = this;\n\n  // Ensure that we have a storage adapter mounted; if not, throw an error.\n  mountStorage();\n\n  tracker.find().forEach(function (chunkInfo) {\n    // Unlink each file\n    FS.Utility.each(chunkInfo.keys || {}, function (key, chunk) {\n      var fileKey = _fileReference({_id: chunkInfo.fileId, collectionName: chunkInfo.collectionName}, chunk, chunkInfo);\n      FS.TempStore.Storage.adapter.remove(fileKey, FS.Utility.noop);\n    });\n\n    // Remove from tracker collection, too\n    tracker.remove({_id: chunkInfo._id});\n  });\n};\n\n/**\n * @method FS.TempStore.createWriteStream\n * @public\n * @param {FS.File} fileObj File to store in temporary storage\n * @param {Number | String} [options]\n * @returns {Stream} Writeable stream\n *\n * `options` of different types mean differnt things:\n * * `undefined` We store the file in one part\n * *(Normal server-side api usage)*\n * * `Number` the number is the part number total\n * *(multipart uploads will use this api)*\n * * `String` the string is the name of the `store` that wants to store file data\n * *(stores that want to sync their data to the rest of the files stores will use this)*\n *\n * > Note: fileObj must be mounted on a `FS.Collection`, it makes no sense to store otherwise\n */\nFS.TempStore.createWriteStream = function(fileObj, options) {\n  var self = this;\n\n  // Ensure that we have a storage adapter mounted; if not, throw an error.\n  mountStorage();\n\n  // If fileObj is not mounted or can't be, throw an error\n  mountFile(fileObj, 'FS.TempStore.createWriteStream');\n\n  // Cache the selector for use multiple times below\n  var selector = {fileId: fileObj._id, collectionName: fileObj.collectionName};\n\n  // TODO, should pass in chunkSum so we don't need to use FS.File for it\n  var chunkSum = fileObj.chunkSum || 1;\n\n  // Add fileObj to tracker collection\n  tracker.upsert(selector, {$setOnInsert: {keys: {}}});\n\n  // Determine how we're using the writeStream\n  var isOnePart = false, isMultiPart = false, isStoreSync = false, chunkNum = 0;\n  if (options === +options) {\n    isMultiPart = true;\n    chunkNum = options;\n  } else if (options === ''+options) {\n    isStoreSync = true;\n  } else {\n    isOnePart = true;\n  }\n\n  // XXX: it should be possible for a store to sync by storing data into the\n  // tempstore - this could be done nicely by setting the store name as string\n  // in the chunk variable?\n  // This store name could be passed on the the fileworker via the uploaded\n  // event\n  // So the uploaded event can return:\n  // undefined - if data is stored into and should sync out to all storage adapters\n  // number - if a chunk has been uploaded\n  // string - if a storage adapter wants to sync its data to the other SA's\n\n  // Find a nice location for the chunk data\n  var fileKey = _fileReference(fileObj, chunkNum);\n\n  // Create the stream as Meteor safe stream\n  var writeStream = FS.TempStore.Storage.adapter.createWriteStream(fileKey);\n\n  // When the stream closes we update the chunkCount\n  writeStream.safeOn('stored', function(result) {\n    // Save key in tracker document\n    var setObj = {};\n    setObj['keys.' + chunkNum] = result.fileKey;\n    tracker.update(selector, {$set: setObj});\n\n    var temp = tracker.findOne(selector);\n\n    if (!temp) {\n      FS.debug && console.log('NOT FOUND FROM TEMPSTORE => EXIT (REMOVED)');\n      return;\n    }\n\n    // Get updated chunkCount\n    var chunkCount = FS.Utility.size(temp.keys);\n\n    // Progress\n    self.emit('progress', fileObj, chunkNum, chunkCount, chunkSum, result);\n\n    var modifier = { $set: {} };\n    if (!fileObj.instance_id) {\n      modifier.$set.instance_id = process.env.COLLECTIONFS_ENV_NAME_UNIQUE_ID ? process.env[process.env.COLLECTIONFS_ENV_NAME_UNIQUE_ID] : process.env.METEOR_PARENT_PID;\n    }\n\n    // If upload is completed\n    if (chunkCount === chunkSum) {\n      // We no longer need the chunk info\n      modifier.$unset = {chunkCount: 1, chunkSum: 1, chunkSize: 1};\n\n      // Check if the file has been uploaded before\n      if (typeof fileObj.uploadedAt === 'undefined') {\n        // We set the uploadedAt date\n        modifier.$set.uploadedAt = new Date();\n      } else {\n        // We have been uploaded so an event were file data is updated is\n        // called synchronizing - so this must be a synchronizedAt?\n        modifier.$set.synchronizedAt = new Date();\n      }\n\n      // Update the fileObject\n      fileObj.update(modifier);\n\n      // Fire ending events\n      var eventName = isStoreSync ? 'synchronized' : 'stored';\n      self.emit(eventName, fileObj, result);\n\n      // XXX is emitting \"ready\" necessary?\n      self.emit('ready', fileObj, chunkCount, result);\n    } else {\n      // Update the chunkCount on the fileObject\n      modifier.$set.chunkCount = chunkCount;\n      fileObj.update(modifier);\n    }\n  });\n\n  // Emit errors\n  writeStream.on('error', function (error) {\n    FS.debug && console.log('TempStore writeStream error:', error);\n    self.emit('error', error, fileObj);\n  });\n\n  return writeStream;\n};\n\n/**\n  * @method FS.TempStore.createReadStream\n  * @public\n  * @param {FS.File} fileObj The file to read\n  * @return {Stream} Returns readable stream\n  *\n  */\nFS.TempStore.createReadStream = function(fileObj) {\n  // Ensure that we have a storage adapter mounted; if not, throw an error.\n  mountStorage();\n\n  // If fileObj is not mounted or can't be, throw an error\n  mountFile(fileObj, 'FS.TempStore.createReadStream');\n\n  FS.debug && console.log('FS.TempStore creating read stream for ' + fileObj._id);\n\n  // Determine how many total chunks there are from the tracker collection\n  var chunkInfo = tracker.findOne({fileId: fileObj._id, collectionName: fileObj.collectionName}) || {};\n  var totalChunks = FS.Utility.size(chunkInfo.keys);\n\n  function getNextStreamFunc(chunk) {\n    return Meteor.bindEnvironment(function(next) {\n      var fileKey = _fileReference(fileObj, chunk);\n      var chunkReadStream = FS.TempStore.Storage.adapter.createReadStream(fileKey);\n      next(chunkReadStream);\n    }, function (error) {\n      throw error;\n    });\n  }\n\n  // Make a combined stream\n  var combinedStream = CombinedStream.create();\n\n  // Add each chunk stream to the combined stream when the previous chunk stream ends\n  var currentChunk = 0;\n  for (var chunk = 0; chunk < totalChunks; chunk++) {\n    combinedStream.append(getNextStreamFunc(chunk));\n  }\n\n  // Return the combined stream\n  return combinedStream;\n};\n"]},"sourceType":"module","hash":"764adc90c287eacf3405930ddd877bcaef5d55c8"}
